
"""
Synthetic Q&A Pair Generator for PILAR/EUCRM Collaboration Research
====================================================================

Credit: Ben Hethslop et al.

This module generates synthetic question-and-answer pairs designed for fine-tuning 
Large Language Models (LLMs) such as Microsoft Phi-4-14B using frameworks like Unsloth.
The generated data encapsulates research on prosocial collaboration, evolutionary 
psychology, and the PILAR (Prospects, Involved, Liked, Agency, Respect) model.

Approach Methodology
--------------------

The synthetic data generation follows a structured, theory-driven approach:

1. **Thematic Foundation**: Questions and answers are grounded in seven core themes
   derived from collaboration research, including the PILAR model, prosocial evolution
   via sub-group level selection (sGLS), inequality aversion, Thorngate's Postulate,
   the Deep Research Agent (DRA), egalitarian behavior, and positive-sum dynamics.

2. **Hypothesis-Driven Design**: Each Q&A pair is anchored to one of five empirical
   hypotheses (H1-H5) that explore the relationships between prosocial orientation,
   inequality aversion, egalitarian structures, learning reticence, and hierarchy
   dynamics. This ensures the dataset validates specific research propositions.

3. **Theoretical Integration**: Questions incorporate established psychological and
   sociological theories (Social Identity Theory, Social Network Analysis, 
   Psychological Safety, Field Theory, Cognitive Dissonance, Inequity Aversion)
   to provide robust theoretical grounding and cross-disciplinary validation.

4. **Stylistic Emulation**: The generator captures the authors' scholarly yet
   accessible tone, blending empirical rigor with evolutionary optimism. Answers
   reflect cautious advocacy for PILAR's unifying potential while acknowledging
   complexity challenges and the need for empirical validation.

5. **Structured Variation**: Through modulo-based cycling of themes, hypotheses,
   theories, and sources, the generator ensures diversity across the dataset while
   maintaining thematic coherence and preventing overfitting to specific patterns.

Critical Need for Synthetic Data Amplification
-----------------------------------------------

The Q&A pairs generated by this module serve as **seed data** that must be further
expanded using a Synthetic Data Generator (SDG) to achieve the scale and diversity
required for effective LLM fine-tuning:

**Rationale for Amplification:**

- **Scale Requirements**: Modern LLM fine-tuning typically requires thousands to
  tens of thousands of examples. The base generator produces 500 pairs, which serves
  as a foundation but is insufficient for robust model adaptation.

- **Diversity Enhancement**: An SDG can generate variations that maintain alignment
  with the core criteria (themes, hypotheses, theories, style) while introducing
  linguistic diversity, alternative phrasings, and novel question formulations that
  prevent model memorization.

- **Criteria Preservation**: The SDG must be configured to preserve the essential
  characteristics of the seed data:
  * Scholarly tone with cautious optimism
  * Hypothesis-driven question structure
  * Integration of specified theories
  * Thematic coherence with PILAR/EUCRM research
  * Source attribution and temporal consistency

- **Quality Assurance**: Generated variations should undergo validation to ensure
  they maintain theoretical accuracy, stylistic consistency, and alignment with
  the research agenda. The seed data provides the quality benchmark.

**Recommended SDG Workflow:**

1. Generate base pairs using this module (500-3000 pairs)
2. Feed pairs into SDG with strict criteria enforcement
3. Generate 5-10x amplification (2,500-30,000 total pairs)
4. Validate sample outputs for criteria alignment
5. Export to JSONL format for LLM fine-tuning

Module Structure: Section Definitions
--------------------------------------

# Style and Core Opinions of Author
    Captures the distinctive writing characteristics, argumentative patterns, and
    rhetorical approaches of the research authors (Hethslop et al.). This includes
    their tendency toward scholarly formality balanced with accessible language,
    cautious optimism about theoretical frameworks, and emphasis on empirical
    validation. The extracted style guides answer generation to authentically
    reflect the authors' voice.

# Areas of Interest (topic_level)
    Defines the disciplinary domains and subject matter focus areas that frame
    the research context. Examples include Psychology, Physics, Economics, and
    Geopolitics. This categorization ensures questions span appropriate intellectual
    territories and maintain interdisciplinary relevance consistent with the
    PILAR model's integration of multiple theoretical frameworks.

# Level of Abstraction
    Specifies the conceptual altitude at which questions and answers operate:
    - **Strategic (Vision-level)**: High-level theoretical frameworks and paradigms
    - **Operational (Project-level)**: Implementation approaches and methodologies
    - **Tactical (Task-level)**: Specific techniques and practical applications
    
    This stratification ensures the dataset covers multiple levels of analysis,
    from abstract theory to concrete practice, supporting diverse use cases.

# Core Themes and Hypotheses
    **Core Themes**: The seven fundamental research areas that structure the dataset:
    1. PILAR model (five pillars, 20 interlinked forces, >30 SGP theories)
    2. Prosocial evolution and sub-group level selection (sGLS)
    3. Inequality aversion in collaboration
    4. Thorngate's Postulate of Commensurate Complexity
    5. Deep Research Agent (DRA) for practical application
    6. Egalitarian behavior and cultural transformation
    7. Positive-sum vs. zero-sum dynamics
    
    **Hypotheses**: Five empirical propositions (H1-H5) that the dataset aims to
    validate through question-answer patterns:
    - H1: PILAR/EUCRM teaching effects on prosocial orientation
    - H2: Inequality aversion's role in prosocial engagement
    - H3: Egalitarian structures' impact on collaboration dynamics
    - H4: Prosociality levels and learning reticence
    - H5: Hierarchy steepness and performance-health balance
    
    **Theories**: Six established frameworks providing theoretical grounding
    **Sources**: Five research documents from which content is derived

# Function to Generate Q&A Pairs
    The core algorithmic component that orchestrates the generation process:
    1. Cycles through themes, hypotheses, theories, and sources using modulo
       arithmetic to ensure balanced representation
    2. Constructs questions using templated patterns that embed hypothesis focus
    3. Generates answers by combining theme-specific content with theoretical
       insights, maintaining the authors' stylistic signature
    4. Packages each pair with metadata (source attribution, timestamp)
    5. Exports to JSONL format compatible with LLM fine-tuning pipelines

Output Format
-------------
The module generates a JSONL (JSON Lines) file where each line contains:
- **question**: Unique ID + hypothesis-driven question text
- **answer**: Thematically grounded response with theoretical integration
- **source**: Attribution to one of five research documents
- **timestamp**: ISO 8601 formatted timestamp (UTC)

This format ensures compatibility with standard LLM fine-tuning frameworks while
maintaining traceability to source materials and temporal context.

Usage
-----
    python qa-pairs-gen.py

The script will generate 'synthetic_qa_phi4.jsonl' in the current directory,
containing the specified number of Q&A pairs ready for SDG amplification and
subsequent LLM fine-tuning.

Dependencies
------------
- json: Standard library for JSONL serialization
- uuid: Standard library for unique identifier generation (imported but not used)
- datetime: Standard library for timestamp generation

Notes
-----
- The generator is deterministic given fixed input lists; for variation, modify
  the core themes, hypotheses, theories, or question templates
- Timestamp is set to a specific research milestone (2025-10-20T12:13:00Z)
- The modulo-based cycling ensures even distribution across all categories
- Generated pairs are designed as seed data requiring the use of LLM's with context
provided by papers for amplification/expansion
"""

import json
import uuid
from datetime import datetime

# Style and Core Opinions of Author
extracted_style = []

# Areas of interest eg. Psychology, Physics, Economics, Geopolitics
topic_level = []

# Level of Abstraction
abstraction = ["Strategic: Vision-level", "Operational: Project-Level", "Tactical: Task-level"]


# Core themes and hypotheses
"""A List of core themes for the data that is being generated"""

core_themes = [
    
]

"""A list of Hypothesese the dataset is aiming to validate"""

hypotheses = [
    
]
theories = [
    # Psychology and Pro Social Example Given
    "Social Identity Theory (SIT)",
    "Social Network Analysis (SNA)",
    "Psychological Safety",
    "Field Theory (Lewin)",
    "Cognitive Dissonance (Festinger)",
    "Inequity Aversion (de Waal)"
]
sources = [
    # Data Sources to Draw From
    "hypothesese2.md", "technology-collaboration.md", "hypothese1.md",
    "abstract.md", "A-Model-Of-Collaboration.pdf"
]

# Function to generate Q&A pairs with authors' style
def generate_qa_pairs():
    # Generated Pairs
    qa_pairs = []
    timestamp = "2025-10-20T12:13:00Z"  # 11:13 PM ACDT = 12:13 PM UTC

    # Set Range of Q&A Pairs
    for i in range(500):
        # Generate unique question ID and base structure
        q_id = f"Q{i+1}"
        # Cycle through configuration lists
        # style = extracted_style[i % len(extracted_style)] if extracted_style else None
        # topic = topic_level[i % len(topic_level)] if topic_level else None
        # abstract_level = abstraction[i % len(abstraction)]
        theme = core_themes[i % len(core_themes)]
        hypo = hypotheses[i % len(hypotheses)]
        theory = theories[i % len(theories)]
        source = sources[i % len(sources)]

        # Construct question with scholarly tone and hypothesis focus
        question_types = [
            f"How might {theme} enhance collaboration viability in light of {hypo}?",
            f"What role does {theory} play in validating {hypo} within {theme}?",
            f"Can {theme} address the challenge posed by {hypo}, drawing on {theory}?",
            f"To what extent does {hypo} influence the efficacy of {theme}, per {theory}?"
        ]
        question = f"{q_id}: {question_types[i % len(question_types)]}"

        # Construct answer with authors' optimistic yet cautious style
        answer_base = {
            "PILAR model": "The PILAR model, with its five pillars and 20 interlinked forces, offers a promising synthesis of over 30 SGP theories, potentially enhancing collaboration viability if applied through idealized conditions.",
            "Prosocial evolution and sGLS": "Prosocial evolution, driven by sGLS, suggests an exponential advantage in hominin collaboration, rooted in savannah ecology, though empirical validation remains a future endeavor.",
            "Inequality aversion in collaboration": "Inequality aversion, a cornerstone of prosociality, punishes unfairness and fosters Respect, yet its impact may wane in hierarchical settings unless mitigated by DRA.",
            "Thorngate’s Postulate": "Thorngate’s Postulate highlights the trade-off between generality, accuracy, and simplicity in PILAR, necessitating AI agents like DRA to bridge this complexity gap.",
            "Deep Research Agent (DRA)": "The DRA, powered by LLMs, acts as an empathetic coach, translating PILAR’s complexity into actionable guidance, though its efficacy hinges on bias mitigation.",
            "Egalitarian behavior and cultural transformation": "Egalitarian behavior stabilizes groups via the communication-respect-liking trio, yet may stifle Agency, a tension we believe can be balanced with careful design.",
            "Positive-sum vs. zero-sum dynamics": "Positive-sum dynamics build CA through trust, countering zero-sum reticence, a challenge we see as addressable with ancestral norm priming."
        }
        theory_insight = {
            "Social Identity Theory (SIT)": "SIT underscores how Liked perceptions shape ingroup cohesion, aligning with PILAR’s evolutionary adaptive mechanisms.",
            "Social Network Analysis (SNA)": "SNA reveals network centrality’s role in Involved perceptions, supporting PILAR’s force dynamics.",
            "Psychological Safety": "Psychological safety fosters Agency, a pillar we deem critical for innovation within PILAR.",
            "Field Theory (Lewin)": "Lewin’s field theory informs Prospects as a function of social forces, a concept we integrate into PILAR’s structure.",
            "Cognitive Dissonance (Festinger)": "Festinger’s dissonance explains Agency’s impact on Liked, a nuance we explore for collaboration resistance.",
            "Inequity Aversion (de Waal)": "de Waal’s inequity aversion links to Respect, reinforcing PILAR’s prosocial foundation."
        }
        answer = f"{answer_base[theme]} We contend that {theory_insight[theory]} offers a robust lens, though further empirical testing is prudent to affirm these insights."

        qa_pairs.append({
            "question": question,
            "answer": answer,
            "source": source,
            "timestamp": timestamp
        })

    return qa_pairs

# Generate and write to .jsonl file
qa_data = generate_qa_pairs()
with open("synthetic_qa_phi4.jsonl", "w", encoding="utf-8") as f:
    for item in qa_data:
        f.write(json.dumps(item, ensure_ascii=False) + "\n")

print("File 'synthetic_qa_phi4.jsonl' has been created with 3000 Q&A pairs.")